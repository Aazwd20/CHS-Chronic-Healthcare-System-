{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "\n",
    "# Load the preprocessed dataset\n",
    "data = pd.read_csv(\"dataset/stroke_data.csv\")\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=[\"stroke\"])\n",
    "y = data[\"stroke\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex                  float64\n",
       "age                  float64\n",
       "hypertension           int64\n",
       "heart_disease          int64\n",
       "ever_married           int64\n",
       "work_type              int64\n",
       "Residence_type         int64\n",
       "avg_glucose_level    float64\n",
       "bmi                  float64\n",
       "smoking_status         int64\n",
       "stroke                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40910 entries, 0 to 40909\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sex                40907 non-null  float64\n",
      " 1   age                40910 non-null  float64\n",
      " 2   hypertension       40910 non-null  int64  \n",
      " 3   heart_disease      40910 non-null  int64  \n",
      " 4   ever_married       40910 non-null  int64  \n",
      " 5   work_type          40910 non-null  int64  \n",
      " 6   Residence_type     40910 non-null  int64  \n",
      " 7   avg_glucose_level  40910 non-null  float64\n",
      " 8   bmi                40910 non-null  float64\n",
      " 9   smoking_status     40910 non-null  int64  \n",
      " 10  stroke             40910 non-null  int64  \n",
      "dtypes: float64(4), int64(7)\n",
      "memory usage: 3.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40910, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40907.000000</td>\n",
       "      <td>40910.000000</td>\n",
       "      <td>40910.000000</td>\n",
       "      <td>40910.000000</td>\n",
       "      <td>40910.000000</td>\n",
       "      <td>40910.000000</td>\n",
       "      <td>40910.000000</td>\n",
       "      <td>40910.000000</td>\n",
       "      <td>40910.000000</td>\n",
       "      <td>40910.000000</td>\n",
       "      <td>40910.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.555162</td>\n",
       "      <td>51.327255</td>\n",
       "      <td>0.213835</td>\n",
       "      <td>0.127719</td>\n",
       "      <td>0.821340</td>\n",
       "      <td>3.461134</td>\n",
       "      <td>0.514886</td>\n",
       "      <td>122.075901</td>\n",
       "      <td>30.406355</td>\n",
       "      <td>0.488609</td>\n",
       "      <td>0.500122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.496954</td>\n",
       "      <td>21.623969</td>\n",
       "      <td>0.410017</td>\n",
       "      <td>0.333781</td>\n",
       "      <td>0.383072</td>\n",
       "      <td>0.780919</td>\n",
       "      <td>0.499784</td>\n",
       "      <td>57.561531</td>\n",
       "      <td>6.835072</td>\n",
       "      <td>0.499876</td>\n",
       "      <td>0.500006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.120000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.750000</td>\n",
       "      <td>25.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>97.920000</td>\n",
       "      <td>29.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>167.590000</td>\n",
       "      <td>34.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>271.740000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                sex           age  hypertension  heart_disease  ever_married  \\\n",
       "count  40907.000000  40910.000000  40910.000000   40910.000000  40910.000000   \n",
       "mean       0.555162     51.327255      0.213835       0.127719      0.821340   \n",
       "std        0.496954     21.623969      0.410017       0.333781      0.383072   \n",
       "min        0.000000     -9.000000      0.000000       0.000000      0.000000   \n",
       "25%        0.000000     35.000000      0.000000       0.000000      1.000000   \n",
       "50%        1.000000     52.000000      0.000000       0.000000      1.000000   \n",
       "75%        1.000000     68.000000      0.000000       0.000000      1.000000   \n",
       "max        1.000000    103.000000      1.000000       1.000000      1.000000   \n",
       "\n",
       "          work_type  Residence_type  avg_glucose_level           bmi  \\\n",
       "count  40910.000000    40910.000000       40910.000000  40910.000000   \n",
       "mean       3.461134        0.514886         122.075901     30.406355   \n",
       "std        0.780919        0.499784          57.561531      6.835072   \n",
       "min        0.000000        0.000000          55.120000     11.500000   \n",
       "25%        3.000000        0.000000          78.750000     25.900000   \n",
       "50%        4.000000        1.000000          97.920000     29.400000   \n",
       "75%        4.000000        1.000000         167.590000     34.100000   \n",
       "max        4.000000        1.000000         271.740000     92.000000   \n",
       "\n",
       "       smoking_status        stroke  \n",
       "count    40910.000000  40910.000000  \n",
       "mean         0.488609      0.500122  \n",
       "std          0.499876      0.500006  \n",
       "min          0.000000      0.000000  \n",
       "25%          0.000000      0.000000  \n",
       "50%          0.000000      1.000000  \n",
       "75%          1.000000      1.000000  \n",
       "max          1.000000      1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>186.21</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex   age  hypertension  heart_disease  ever_married  work_type  \\\n",
       "0  1.0  63.0             0              1             1          4   \n",
       "1  1.0  42.0             0              1             1          4   \n",
       "2  0.0  61.0             0              0             1          4   \n",
       "3  1.0  41.0             1              0             1          3   \n",
       "4  1.0  85.0             0              0             1          4   \n",
       "\n",
       "   Residence_type  avg_glucose_level   bmi  smoking_status  stroke  \n",
       "0               1             228.69  36.6               1       1  \n",
       "1               0             105.92  32.5               0       1  \n",
       "2               1             171.23  34.4               1       1  \n",
       "3               0             174.12  24.0               0       1  \n",
       "4               1             186.21  29.0               1       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex                  3\n",
       "age                  0\n",
       "hypertension         0\n",
       "heart_disease        0\n",
       "ever_married         0\n",
       "work_type            0\n",
       "Residence_type       0\n",
       "avg_glucose_level    0\n",
       "bmi                  0\n",
       "smoking_status       0\n",
       "stroke               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()\n",
    "# This will give you the count of missing values in each column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Missing Values\n",
    "# Impute missing values in the 'sex' column with the most frequent value\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "data[['sex']] = imputer.fit_transform(data[['sex']])\n",
    "\n",
    "# Encoding Categorical Variables (if needed)\n",
    "# Assuming all categorical variables are already encoded\n",
    "\n",
    "# Feature Scaling (if needed)\n",
    "scaler = StandardScaler()\n",
    "numerical_columns = ['age', 'avg_glucose_level', 'bmi']\n",
    "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
    "\n",
    "# Splitting Data into Training and Testing Sets\n",
    "X = data.drop('stroke', axis=1)\n",
    "y = data['stroke']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Balancing the Dataset (if needed)\n",
    "class_counts = y_train.value_counts()\n",
    "# If classes are imbalanced, consider using techniques like oversampling or undersampling\n",
    "\n",
    "# Now you have preprocessed data ready for training your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9984111464189684\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluating the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "Accuracy: 0.9984111464189684\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4022\n",
      "           1       1.00      1.00      1.00      4160\n",
      "\n",
      "    accuracy                           1.00      8182\n",
      "   macro avg       1.00      1.00      1.00      8182\n",
      "weighted avg       1.00      1.00      1.00      8182\n",
      "\n",
      "\n",
      "Decision Tree Classifier:\n",
      "Accuracy: 0.9998777804937669\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4022\n",
      "           1       1.00      1.00      1.00      4160\n",
      "\n",
      "    accuracy                           1.00      8182\n",
      "   macro avg       1.00      1.00      1.00      8182\n",
      "weighted avg       1.00      1.00      1.00      8182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Decision Tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the test set using Decision Tree\n",
    "dt_y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate Random Forest Classifier\n",
    "print(\"Random Forest Classifier:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Evaluate Decision Tree Classifier\n",
    "print(\"\\nDecision Tree Classifier:\")\n",
    "dt_accuracy = accuracy_score(y_test, dt_y_pred)\n",
    "print(\"Accuracy:\", dt_accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, dt_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Classifier:\n",
      "Accuracy: 0.8813248594475678\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.78      0.87      4022\n",
      "           1       0.82      0.98      0.89      4160\n",
      "\n",
      "    accuracy                           0.88      8182\n",
      "   macro avg       0.90      0.88      0.88      8182\n",
      "weighted avg       0.90      0.88      0.88      8182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a K-Nearest Neighbors Classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions for KNN Classifier\n",
    "knn_y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate KNN Classifier\n",
    "print(\"K-Nearest Neighbors Classifier:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, knn_y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, knn_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best parameters for Decision Tree: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\n",
      "Random Forest Classifier:\n",
      "Accuracy: 0.9982889269127353\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4022\n",
      "           1       1.00      1.00      1.00      4160\n",
      "\n",
      "    accuracy                           1.00      8182\n",
      "   macro avg       1.00      1.00      1.00      8182\n",
      "weighted avg       1.00      1.00      1.00      8182\n",
      "\n",
      "\n",
      "Decision Tree Classifier:\n",
      "Accuracy: 0.9998777804937669\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4022\n",
      "           1       1.00      1.00      1.00      4160\n",
      "\n",
      "    accuracy                           1.00      8182\n",
      "   macro avg       1.00      1.00      1.00      8182\n",
      "weighted avg       1.00      1.00      1.00      8182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grids for Random Forest and Decision Tree classifiers\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "dt_param_grid = {\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Instantiate Random Forest and Decision Tree classifiers\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Instantiate GridSearchCV for Random Forest and Decision Tree classifiers\n",
    "rf_grid_search = GridSearchCV(rf_classifier, rf_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "dt_grid_search = GridSearchCV(dt_classifier, dt_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the models\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "dt_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters for Random Forest\n",
    "print(\"Best parameters for Random Forest:\", rf_grid_search.best_params_)\n",
    "\n",
    "# Best parameters for Decision Tree\n",
    "print(\"Best parameters for Decision Tree:\", dt_grid_search.best_params_)\n",
    "\n",
    "# Predicting on the test set using best estimators from grid search\n",
    "rf_y_pred = rf_grid_search.predict(X_test)\n",
    "dt_y_pred = dt_grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate Random Forest Classifier\n",
    "print(\"\\nRandom Forest Classifier:\")\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "print(\"Accuracy:\", rf_accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, rf_y_pred))\n",
    "\n",
    "# Evaluate Decision Tree Classifier\n",
    "print(\"\\nDecision Tree Classifier:\")\n",
    "dt_accuracy = accuracy_score(y_test, dt_y_pred)\n",
    "print(\"Accuracy:\", dt_accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, dt_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for XGBoost: {'colsample_bytree': 1.0, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 300, 'reg_alpha': 0, 'reg_lambda': 1, 'subsample': 1.0}\n",
      "\n",
      "XGBoost Classifier:\n",
      "Accuracy: 0.9996333414813005\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4022\n",
      "           1       1.00      1.00      1.00      4160\n",
      "\n",
      "    accuracy                           1.00      8182\n",
      "   macro avg       1.00      1.00      1.00      8182\n",
      "weighted avg       1.00      1.00      1.00      8182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Instantiate XGBoost classifier\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "\n",
    "# Define parameter grid for XGBoost classifier\n",
    "xgb_param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV for XGBoost classifier\n",
    "xgb_grid_search = GridSearchCV(xgb_classifier, xgb_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "xgb_grid_search.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Best parameters for XGBoost\n",
    "print(\"Best parameters for XGBoost:\", xgb_grid_search.best_params_)\n",
    "\n",
    "# Predicting on the test set using best estimator from grid search\n",
    "xgb_y_pred = xgb_grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate XGBoost Classifier\n",
    "print(\"\\nXGBoost Classifier:\")\n",
    "xgb_accuracy = accuracy_score(y_test_encoded, xgb_y_pred)\n",
    "print(\"Accuracy:\", xgb_accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_encoded, xgb_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for LightGBM: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 200}\n",
      "Best LightGBM Classifier:\n",
      "Accuracy: 0.8510525070955535\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.98      0.92     42795\n",
      "         1.0       0.00      0.00      0.00       944\n",
      "         2.0       0.56      0.18      0.27      6997\n",
      "\n",
      "    accuracy                           0.85     50736\n",
      "   macro avg       0.48      0.39      0.40     50736\n",
      "weighted avg       0.81      0.85      0.81     50736\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zawad\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Zawad\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Zawad\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize LightGBM Classifier\n",
    "lgb_classifier = LGBMClassifier(random_state=42)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features using RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the parameter grid for LightGBM\n",
    "param_grid_lgb = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "# Initialize LightGBM Classifier\n",
    "best_lgb_classifier = LGBMClassifier(num_leaves=50, max_depth=7, learning_rate=0.05, n_estimators=300, random_state=42)\n",
    "best_lgb_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Perform GridSearchCV for LightGBM\n",
    "grid_search_lgb = GridSearchCV(lgb_classifier, param_grid_lgb, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_lgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters for LightGBM\n",
    "best_params_lgb = grid_search_lgb.best_params_\n",
    "print(\"Best Parameters for LightGBM:\", best_params_lgb)\n",
    "\n",
    "# Train the LightGBM classifier with the best parameters\n",
    "best_lgb_classifier = LGBMClassifier(**best_params_lgb, random_state=42)\n",
    "best_lgb_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions for the best LightGBM Classifier\n",
    "best_lgb_y_pred = best_lgb_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the best LightGBM Classifier\n",
    "print(\"Best LightGBM Classifier:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, best_lgb_y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, best_lgb_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m X_test[numerical_columns] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_test[numerical_columns])\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Define the ANN model\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m     17\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],)),\n\u001b[0;32m     18\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.2\u001b[39m),\n\u001b[0;32m     19\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m32\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     20\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.2\u001b[39m),\n\u001b[0;32m     21\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m ])\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[0;32m     25\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "data[['sex']] = imputer.fit_transform(data[['sex']])\n",
    "\n",
    "# Splitting Data into Training and Testing Sets\n",
    "X = data.drop('stroke', axis=1)\n",
    "y = data['stroke']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "numerical_columns = ['age', 'avg_glucose_level', 'bmi']\n",
    "X_train[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])\n",
    "X_test[numerical_columns] = scaler.transform(X_test[numerical_columns])\n",
    "\n",
    "# Define the ANN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
