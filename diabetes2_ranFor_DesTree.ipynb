{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "\n",
    "# Load the preprocessed dataset\n",
    "data = pd.read_csv(\"dataset/diabetes_012_health_indicators_BRFSS2015.csv\")\n",
    "\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=[\"Diabetes_012\"])\n",
    "y = data[\"Diabetes_012\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes_012            float64\n",
       "HighBP                  float64\n",
       "HighChol                float64\n",
       "CholCheck               float64\n",
       "BMI                     float64\n",
       "Smoker                  float64\n",
       "Stroke                  float64\n",
       "HeartDiseaseorAttack    float64\n",
       "PhysActivity            float64\n",
       "Fruits                  float64\n",
       "Veggies                 float64\n",
       "HvyAlcoholConsump       float64\n",
       "AnyHealthcare           float64\n",
       "NoDocbcCost             float64\n",
       "GenHlth                 float64\n",
       "MentHlth                float64\n",
       "PhysHlth                float64\n",
       "DiffWalk                float64\n",
       "Sex                     float64\n",
       "Age                     float64\n",
       "Education               float64\n",
       "Income                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 253680 entries, 0 to 253679\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   Diabetes_012          253680 non-null  float64\n",
      " 1   HighBP                253680 non-null  float64\n",
      " 2   HighChol              253680 non-null  float64\n",
      " 3   CholCheck             253680 non-null  float64\n",
      " 4   BMI                   253680 non-null  float64\n",
      " 5   Smoker                253680 non-null  float64\n",
      " 6   Stroke                253680 non-null  float64\n",
      " 7   HeartDiseaseorAttack  253680 non-null  float64\n",
      " 8   PhysActivity          253680 non-null  float64\n",
      " 9   Fruits                253680 non-null  float64\n",
      " 10  Veggies               253680 non-null  float64\n",
      " 11  HvyAlcoholConsump     253680 non-null  float64\n",
      " 12  AnyHealthcare         253680 non-null  float64\n",
      " 13  NoDocbcCost           253680 non-null  float64\n",
      " 14  GenHlth               253680 non-null  float64\n",
      " 15  MentHlth              253680 non-null  float64\n",
      " 16  PhysHlth              253680 non-null  float64\n",
      " 17  DiffWalk              253680 non-null  float64\n",
      " 18  Sex                   253680 non-null  float64\n",
      " 19  Age                   253680 non-null  float64\n",
      " 20  Education             253680 non-null  float64\n",
      " 21  Income                253680 non-null  float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 42.6 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253680, 22)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_012</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.296921</td>\n",
       "      <td>0.429001</td>\n",
       "      <td>0.424121</td>\n",
       "      <td>0.962670</td>\n",
       "      <td>28.382364</td>\n",
       "      <td>0.443169</td>\n",
       "      <td>0.040571</td>\n",
       "      <td>0.094186</td>\n",
       "      <td>0.756544</td>\n",
       "      <td>0.634256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951053</td>\n",
       "      <td>0.084177</td>\n",
       "      <td>2.511392</td>\n",
       "      <td>3.184772</td>\n",
       "      <td>4.242081</td>\n",
       "      <td>0.168224</td>\n",
       "      <td>0.440342</td>\n",
       "      <td>8.032119</td>\n",
       "      <td>5.050434</td>\n",
       "      <td>6.053875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.698160</td>\n",
       "      <td>0.494934</td>\n",
       "      <td>0.494210</td>\n",
       "      <td>0.189571</td>\n",
       "      <td>6.608694</td>\n",
       "      <td>0.496761</td>\n",
       "      <td>0.197294</td>\n",
       "      <td>0.292087</td>\n",
       "      <td>0.429169</td>\n",
       "      <td>0.481639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215759</td>\n",
       "      <td>0.277654</td>\n",
       "      <td>1.068477</td>\n",
       "      <td>7.412847</td>\n",
       "      <td>8.717951</td>\n",
       "      <td>0.374066</td>\n",
       "      <td>0.496429</td>\n",
       "      <td>3.054220</td>\n",
       "      <td>0.985774</td>\n",
       "      <td>2.071148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Diabetes_012         HighBP       HighChol      CholCheck  \\\n",
       "count  253680.000000  253680.000000  253680.000000  253680.000000   \n",
       "mean        0.296921       0.429001       0.424121       0.962670   \n",
       "std         0.698160       0.494934       0.494210       0.189571   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       1.000000   \n",
       "50%         0.000000       0.000000       0.000000       1.000000   \n",
       "75%         0.000000       1.000000       1.000000       1.000000   \n",
       "max         2.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                 BMI         Smoker         Stroke  HeartDiseaseorAttack  \\\n",
       "count  253680.000000  253680.000000  253680.000000         253680.000000   \n",
       "mean       28.382364       0.443169       0.040571              0.094186   \n",
       "std         6.608694       0.496761       0.197294              0.292087   \n",
       "min        12.000000       0.000000       0.000000              0.000000   \n",
       "25%        24.000000       0.000000       0.000000              0.000000   \n",
       "50%        27.000000       0.000000       0.000000              0.000000   \n",
       "75%        31.000000       1.000000       0.000000              0.000000   \n",
       "max        98.000000       1.000000       1.000000              1.000000   \n",
       "\n",
       "        PhysActivity         Fruits  ...  AnyHealthcare    NoDocbcCost  \\\n",
       "count  253680.000000  253680.000000  ...  253680.000000  253680.000000   \n",
       "mean        0.756544       0.634256  ...       0.951053       0.084177   \n",
       "std         0.429169       0.481639  ...       0.215759       0.277654   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         1.000000       0.000000  ...       1.000000       0.000000   \n",
       "50%         1.000000       1.000000  ...       1.000000       0.000000   \n",
       "75%         1.000000       1.000000  ...       1.000000       0.000000   \n",
       "max         1.000000       1.000000  ...       1.000000       1.000000   \n",
       "\n",
       "             GenHlth       MentHlth       PhysHlth       DiffWalk  \\\n",
       "count  253680.000000  253680.000000  253680.000000  253680.000000   \n",
       "mean        2.511392       3.184772       4.242081       0.168224   \n",
       "std         1.068477       7.412847       8.717951       0.374066   \n",
       "min         1.000000       0.000000       0.000000       0.000000   \n",
       "25%         2.000000       0.000000       0.000000       0.000000   \n",
       "50%         2.000000       0.000000       0.000000       0.000000   \n",
       "75%         3.000000       2.000000       3.000000       0.000000   \n",
       "max         5.000000      30.000000      30.000000       1.000000   \n",
       "\n",
       "                 Sex            Age      Education         Income  \n",
       "count  253680.000000  253680.000000  253680.000000  253680.000000  \n",
       "mean        0.440342       8.032119       5.050434       6.053875  \n",
       "std         0.496429       3.054220       0.985774       2.071148  \n",
       "min         0.000000       1.000000       1.000000       1.000000  \n",
       "25%         0.000000       6.000000       4.000000       5.000000  \n",
       "50%         0.000000       8.000000       5.000000       7.000000  \n",
       "75%         1.000000      10.000000       6.000000       8.000000  \n",
       "max         1.000000      13.000000       6.000000       8.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# 2. Scale numerical features using MinMaxScaler\n",
    "numeric_cols = data.select_dtypes(include=['float64']).columns\n",
    "scaler = MinMaxScaler()\n",
    "data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Diabetes_012  HighBP  HighChol  CholCheck       BMI  Smoker  Stroke  \\\n",
      "0           0.0     1.0       1.0        1.0  0.325581     1.0     0.0   \n",
      "1           0.0     0.0       0.0        0.0  0.151163     1.0     0.0   \n",
      "2           0.0     1.0       1.0        1.0  0.186047     0.0     0.0   \n",
      "3           0.0     1.0       0.0        1.0  0.174419     0.0     0.0   \n",
      "4           0.0     1.0       1.0        1.0  0.139535     0.0     0.0   \n",
      "\n",
      "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
      "0                   0.0           0.0     0.0  ...            1.0   \n",
      "1                   0.0           1.0     0.0  ...            0.0   \n",
      "2                   0.0           0.0     1.0  ...            1.0   \n",
      "3                   0.0           1.0     1.0  ...            1.0   \n",
      "4                   0.0           1.0     1.0  ...            1.0   \n",
      "\n",
      "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex       Age  \\\n",
      "0          0.0     1.00       0.6       0.5       1.0  0.0  0.666667   \n",
      "1          1.0     0.50       0.0       0.0       0.0  0.0  0.500000   \n",
      "2          1.0     1.00       1.0       1.0       1.0  0.0  0.666667   \n",
      "3          0.0     0.25       0.0       0.0       0.0  0.0  0.833333   \n",
      "4          0.0     0.25       0.1       0.0       0.0  0.0  0.833333   \n",
      "\n",
      "   Education    Income  \n",
      "0        0.6  0.285714  \n",
      "1        1.0  0.000000  \n",
      "2        0.6  1.000000  \n",
      "3        0.4  0.714286  \n",
      "4        0.8  0.428571  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop specified columns from features\n",
    "X = data.drop(columns=['Diabetes_012', 'Education', 'Income', 'DiffWalk'])\n",
    "\n",
    "# Separate the target variable\n",
    "y = data['Diabetes_012']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m rf_classifier \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Train the Random Forest classifier\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mrf_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Make predictions on the testing set\u001b[39;00m\n\u001b[0;32m     16\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m rf_classifier\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:421\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    414\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSum of y is not strictly positive which \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis necessary for Poisson regression.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m         )\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_samples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m--> 421\u001b[0m y, expanded_class_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_y_class_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m!=\u001b[39m DOUBLE \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m y\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mcontiguous:\n\u001b[0;32m    424\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(y, dtype\u001b[38;5;241m=\u001b[39mDOUBLE)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:831\u001b[0m, in \u001b[0;36mForestClassifier._validate_y_class_weight\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_y_class_weight\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[1;32m--> 831\u001b[0m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(y)\n\u001b[0;32m    834\u001b[0m     expanded_class_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\multiclass.py:221\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    213\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m ]:\n\u001b[1;32m--> 221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Maybe you are trying to fit a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier, which expects discrete classes on a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression target with continuous values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    225\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the Random Forest classifier\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Random Forest Classifier\n",
    "print(\"Random Forest Classifier:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, rf_y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, rf_y_pred))\n",
    "\n",
    "# Evaluate Decision Tree Classifier\n",
    "print(\"\\nDecision Tree Classifier:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, dt_y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, dt_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age        bp        sg        al        su  rbc  pc  pcc  ba  \\\n",
      "0 -0.216167  0.254214  0.421486  0.076249 -0.380269    1   2    1   1   \n",
      "1 -2.627830 -1.972476  0.421486  2.363728 -0.380269    1   2    1   1   \n",
      "2  0.607327  0.254214 -1.421074  0.838742  2.507853    2   2    1   1   \n",
      "3 -0.216167 -0.488016 -2.342354  2.363728 -0.380269    2   0    2   1   \n",
      "4 -0.039704  0.254214 -1.421074  0.838742 -0.380269    2   2    1   1   \n",
      "\n",
      "        bgr  ...       pcv        wc        rc  htn  dm  cad  appet  pe  ane  \\\n",
      "0 -0.283841  ...  0.569881 -0.206202  0.481295    2   5    2      0   1    1   \n",
      "1 -0.572370  ... -0.098536 -0.818559  0.090447    1   4    2      0   1    1   \n",
      "2  3.676881  ... -0.878356 -0.308261  0.090447    1   5    2      2   1    2   \n",
      "3 -0.336301  ... -0.766953 -0.580420 -0.788961    2   4    2      2   2    2   \n",
      "4 -0.480565  ... -0.432744 -0.376301 -0.104977    1   4    2      0   1    1   \n",
      "\n",
      "   classification  \n",
      "0             ckd  \n",
      "1             ckd  \n",
      "2             ckd  \n",
      "3             ckd  \n",
      "4             ckd  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert 'rc' column to numeric\n",
    "data['rc'] = pd.to_numeric(data['rc'], errors='coerce')\n",
    "\n",
    "# Handling Missing Values for Numerical Columns\n",
    "numerical_imputer = SimpleImputer(strategy='median')  \n",
    "data[['pcv', 'wc', 'rc']] = numerical_imputer.fit_transform(data[['pcv', 'wc', 'rc']])\n",
    "\n",
    "# Display the preprocessed data\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop specified columns from features\n",
    "# X = data.drop(columns=['Diabetes_012', 'Education', 'Income', 'DiffWalk'])\n",
    "\n",
    "# # Separate the target variable\n",
    "# y = data['Diabetes_012']\n",
    "\n",
    "# # Now you can proceed with preprocessing the data, splitting it into training and testing sets, and further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X = data.drop('classification', axis=1)\n",
    "y = data['classification']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluating the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ckd       1.00      1.00      1.00        52\n",
      "      notckd       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        80\n",
      "   macro avg       1.00      1.00      1.00        80\n",
      "weighted avg       1.00      1.00      1.00        80\n",
      "\n",
      "\n",
      "Decision Tree Classifier:\n",
      "Accuracy: 0.9875\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ckd       1.00      0.98      0.99        52\n",
      "        ckd\t       0.00      0.00      0.00         0\n",
      "      notckd       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           0.99        80\n",
      "   macro avg       0.67      0.66      0.66        80\n",
      "weighted avg       1.00      0.99      0.99        80\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zawad\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Zawad\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Zawad\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train Decision Tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the test set using Decision Tree\n",
    "dt_y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate Random Forest Classifier\n",
    "print(\"Random Forest Classifier:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Evaluate Decision Tree Classifier\n",
    "print(\"\\nDecision Tree Classifier:\")\n",
    "dt_accuracy = accuracy_score(y_test, dt_y_pred)\n",
    "print(\"Accuracy:\", dt_accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, dt_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Classifier:\n",
      "Accuracy: 0.9875\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ckd       1.00      0.98      0.99        52\n",
      "      notckd       0.97      1.00      0.98        28\n",
      "\n",
      "    accuracy                           0.99        80\n",
      "   macro avg       0.98      0.99      0.99        80\n",
      "weighted avg       0.99      0.99      0.99        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a K-Nearest Neighbors Classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions for KNN Classifier\n",
    "knn_y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate KNN Classifier\n",
    "print(\"K-Nearest Neighbors Classifier:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, knn_y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, knn_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zawad\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Zawad\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best parameters for Decision Tree: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "\n",
      "Random Forest Classifier:\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ckd       1.00      1.00      1.00        52\n",
      "      notckd       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        80\n",
      "   macro avg       1.00      1.00      1.00        80\n",
      "weighted avg       1.00      1.00      1.00        80\n",
      "\n",
      "\n",
      "Decision Tree Classifier:\n",
      "Accuracy: 0.975\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ckd       0.98      0.98      0.98        52\n",
      "      notckd       0.96      0.96      0.96        28\n",
      "\n",
      "    accuracy                           0.97        80\n",
      "   macro avg       0.97      0.97      0.97        80\n",
      "weighted avg       0.97      0.97      0.97        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grids for Random Forest and Decision Tree classifiers\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "dt_param_grid = {\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Instantiate Random Forest and Decision Tree classifiers\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Instantiate GridSearchCV for Random Forest and Decision Tree classifiers\n",
    "rf_grid_search = GridSearchCV(rf_classifier, rf_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "dt_grid_search = GridSearchCV(dt_classifier, dt_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the models\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "dt_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters for Random Forest\n",
    "print(\"Best parameters for Random Forest:\", rf_grid_search.best_params_)\n",
    "\n",
    "# Best parameters for Decision Tree\n",
    "print(\"Best parameters for Decision Tree:\", dt_grid_search.best_params_)\n",
    "\n",
    "# Predicting on the test set using best estimators from grid search\n",
    "rf_y_pred = rf_grid_search.predict(X_test)\n",
    "dt_y_pred = dt_grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate Random Forest Classifier\n",
    "print(\"\\nRandom Forest Classifier:\")\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "print(\"Accuracy:\", rf_accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, rf_y_pred))\n",
    "\n",
    "# Evaluate Decision Tree Classifier\n",
    "print(\"\\nDecision Tree Classifier:\")\n",
    "dt_accuracy = accuracy_score(y_test, dt_y_pred)\n",
    "print(\"Accuracy:\", dt_accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, dt_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zawad\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for XGBoost: {'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300, 'reg_alpha': 0, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "\n",
      "XGBoost Classifier:\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        52\n",
      "           2       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        80\n",
      "   macro avg       1.00      1.00      1.00        80\n",
      "weighted avg       1.00      1.00      1.00        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Instantiate XGBoost classifier\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "\n",
    "# Define parameter grid for XGBoost classifier\n",
    "xgb_param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV for XGBoost classifier\n",
    "xgb_grid_search = GridSearchCV(xgb_classifier, xgb_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "xgb_grid_search.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Best parameters for XGBoost\n",
    "print(\"Best parameters for XGBoost:\", xgb_grid_search.best_params_)\n",
    "\n",
    "# Predicting on the test set using best estimator from grid search\n",
    "xgb_y_pred = xgb_grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate XGBoost Classifier\n",
    "print(\"\\nXGBoost Classifier:\")\n",
    "xgb_accuracy = accuracy_score(y_test_encoded, xgb_y_pred)\n",
    "print(\"Accuracy:\", xgb_accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_encoded, xgb_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for LightGBM: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 200}\n",
      "Best LightGBM Classifier:\n",
      "Accuracy: 0.8510525070955535\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.98      0.92     42795\n",
      "         1.0       0.00      0.00      0.00       944\n",
      "         2.0       0.56      0.18      0.27      6997\n",
      "\n",
      "    accuracy                           0.85     50736\n",
      "   macro avg       0.48      0.39      0.40     50736\n",
      "weighted avg       0.81      0.85      0.81     50736\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zawad\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Zawad\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Zawad\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"dataset/diabetes_012_health_indicators_BRFSS2015.csv\")\n",
    "\n",
    "# Define and preprocess your features and target variable\n",
    "X = data.drop(columns=['Diabetes_012', 'Education', 'Income', 'DiffWalk'])\n",
    "y = data['Diabetes_012']\n",
    "\n",
    "# Initialize LightGBM Classifier\n",
    "lgb_classifier = LGBMClassifier(random_state=42)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features using RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the parameter grid for LightGBM\n",
    "param_grid_lgb = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "# Initialize LightGBM Classifier\n",
    "best_lgb_classifier = LGBMClassifier(num_leaves=50, max_depth=7, learning_rate=0.05, n_estimators=300, random_state=42)\n",
    "best_lgb_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Perform GridSearchCV for LightGBM\n",
    "grid_search_lgb = GridSearchCV(lgb_classifier, param_grid_lgb, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_lgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters for LightGBM\n",
    "best_params_lgb = grid_search_lgb.best_params_\n",
    "print(\"Best Parameters for LightGBM:\", best_params_lgb)\n",
    "\n",
    "# Train the LightGBM classifier with the best parameters\n",
    "best_lgb_classifier = LGBMClassifier(**best_params_lgb, random_state=42)\n",
    "best_lgb_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions for the best LightGBM Classifier\n",
    "best_lgb_y_pred = best_lgb_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the best LightGBM Classifier\n",
    "print(\"Best LightGBM Classifier:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, best_lgb_y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, best_lgb_y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
