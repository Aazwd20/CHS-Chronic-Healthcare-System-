{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "\n",
    "# Load the preprocessed dataset\n",
    "data = pd.read_csv(\"dataset/kidney_disease.csv\")\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=[\"classification\"])\n",
    "y = data[\"classification\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 26)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age        bp        sg        al        su  rbc  pc  pcc  ba  \\\n",
      "0 -0.216167  0.254214  0.421486  0.076249 -0.380269    1   2    1   1   \n",
      "1 -2.627830 -1.972476  0.421486  2.363728 -0.380269    1   2    1   1   \n",
      "2  0.607327  0.254214 -1.421074  0.838742  2.507853    2   2    1   1   \n",
      "3 -0.216167 -0.488016 -2.342354  2.363728 -0.380269    2   0    2   1   \n",
      "4 -0.039704  0.254214 -1.421074  0.838742 -0.380269    2   2    1   1   \n",
      "\n",
      "        bgr  ...       pcv        wc        rc  htn  dm  cad  appet  pe  ane  \\\n",
      "0 -0.283841  ...  0.569881 -0.206202  0.481295    2   5    2      0   1    1   \n",
      "1 -0.572370  ... -0.098536 -0.818559       NaN    1   4    2      0   1    1   \n",
      "2  3.676881  ... -0.878356 -0.308261       NaN    1   5    2      2   1    2   \n",
      "3 -0.336301  ... -0.766953 -0.580420 -0.788961    2   4    2      2   2    2   \n",
      "4 -0.480565  ... -0.432744 -0.376301 -0.104977    1   4    2      0   1    1   \n",
      "\n",
      "   classification  \n",
      "0             ckd  \n",
      "1             ckd  \n",
      "2             ckd  \n",
      "3             ckd  \n",
      "4             ckd  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "\n",
    "# Handling Missing Values\n",
    "imputer = SimpleImputer(strategy='most_frequent')  \n",
    "data[['age', 'bp', 'sg', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo']] = imputer.fit_transform(data[['age', 'bp', 'sg', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo']])\n",
    "\n",
    "# For categorical columns\n",
    "categorical_cols = ['rbc', 'pc', 'pcc', 'ba', 'pcv', 'wc', 'rc', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane']\n",
    "for col in categorical_cols:\n",
    "    data[col].fillna('missing', inplace=True)  \n",
    "\n",
    "# Convert object columns to numeric\n",
    "binary_cols = ['rbc', 'pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane']\n",
    "label_encoder = LabelEncoder()\n",
    "for col in binary_cols:\n",
    "    data[col] = label_encoder.fit_transform(data[col])\n",
    "\n",
    "# Convert remaining object columns to numeric\n",
    "data['pcv'] = pd.to_numeric(data['pcv'], errors='coerce')\n",
    "data['wc'] = pd.to_numeric(data['wc'], errors='coerce')\n",
    "data['rc'] = pd.to_numeric(data['rc'], errors='coerce')\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = ['age', 'bp', 'sg', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wc', 'rc']\n",
    "data[numerical_cols] = scaler.fit_transform(data[numerical_cols])\n",
    "\n",
    "# Drop Unnecessary Columns\n",
    "data.drop(['id'], axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age        bp        sg        al        su  rbc  pc  pcc  ba  \\\n",
      "0 -0.216167  0.254214  0.421486  0.076249 -0.380269    1   2    1   1   \n",
      "1 -2.627830 -1.972476  0.421486  2.363728 -0.380269    1   2    1   1   \n",
      "2  0.607327  0.254214 -1.421074  0.838742  2.507853    2   2    1   1   \n",
      "3 -0.216167 -0.488016 -2.342354  2.363728 -0.380269    2   0    2   1   \n",
      "4 -0.039704  0.254214 -1.421074  0.838742 -0.380269    2   2    1   1   \n",
      "\n",
      "        bgr  ...       pcv        wc        rc  htn  dm  cad  appet  pe  ane  \\\n",
      "0 -0.283841  ...  0.569881 -0.206202  0.481295    2   5    2      0   1    1   \n",
      "1 -0.572370  ... -0.098536 -0.818559  0.090447    1   4    2      0   1    1   \n",
      "2  3.676881  ... -0.878356 -0.308261  0.090447    1   5    2      2   1    2   \n",
      "3 -0.336301  ... -0.766953 -0.580420 -0.788961    2   4    2      2   2    2   \n",
      "4 -0.480565  ... -0.432744 -0.376301 -0.104977    1   4    2      0   1    1   \n",
      "\n",
      "   classification  \n",
      "0             ckd  \n",
      "1             ckd  \n",
      "2             ckd  \n",
      "3             ckd  \n",
      "4             ckd  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert 'rc' column to numeric\n",
    "data['rc'] = pd.to_numeric(data['rc'], errors='coerce')\n",
    "\n",
    "# Handling Missing Values for Numerical Columns\n",
    "numerical_imputer = SimpleImputer(strategy='median')  \n",
    "data[['pcv', 'wc', 'rc']] = numerical_imputer.fit_transform(data[['pcv', 'wc', 'rc']])\n",
    "\n",
    "# Display the preprocessed data\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert object columns to numeric\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_cols = ['rbc', 'pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane']\n",
    "for col in categorical_cols:\n",
    "    data[col] = label_encoder.fit_transform(data[col])\n",
    "\n",
    "# Handling Missing Values\n",
    "imputer = SimpleImputer(strategy='most_frequent')  \n",
    "data = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "\n",
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X = data.drop('classification', axis=1)\n",
    "y = data['classification']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Add Gaussian noise to numerical features\n",
    "numerical_columns = ['age', 'bp', 'sg', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wc', 'rc']\n",
    "noise_std = 0.1  # Adjust this value based on the level of noise desired\n",
    "for col in numerical_columns:\n",
    "    noise_train = np.random.normal(0, noise_std, size=X_train[col].shape)\n",
    "    X_train[col] += noise_train\n",
    "    noise_test = np.random.normal(0, noise_std, size=X_test[col].shape)\n",
    "    X_test[col] += noise_test\n",
    "\n",
    "# Ensure that the values stay within bounds (0 and 1 for some features)\n",
    "X_train = np.clip(X_train, 0, 1)\n",
    "X_test = np.clip(X_test, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert object columns to numeric\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_cols = ['rbc', 'pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane']\n",
    "for col in categorical_cols:\n",
    "    data[col] = label_encoder.fit_transform(data[col])\n",
    "\n",
    "# Handling Missing Values\n",
    "imputer = SimpleImputer(strategy='most_frequent')  \n",
    "data = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "\n",
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X = data.drop('classification', axis=1)\n",
    "y = data['classification']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Add more Gaussian noise to numerical features\n",
    "numerical_columns = ['age', 'bp', 'sg', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wc', 'rc']\n",
    "noise_std = 0.2  # Increased noise level\n",
    "for col in numerical_columns:\n",
    "    noise_train = np.random.normal(0, noise_std, size=X_train[col].shape)\n",
    "    X_train[col] += noise_train\n",
    "    noise_test = np.random.normal(0, noise_std, size=X_test[col].shape)\n",
    "    X_test[col] += noise_test\n",
    "\n",
    "# Ensure that the values stay within bounds (0 and 1 for some features)\n",
    "X_train = np.clip(X_train, 0, 1)\n",
    "X_test = np.clip(X_test, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.975\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluating the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "Accuracy: 0.975\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ckd       0.98      0.98      0.98        52\n",
      "      notckd       0.96      0.96      0.96        28\n",
      "\n",
      "    accuracy                           0.97        80\n",
      "   macro avg       0.97      0.97      0.97        80\n",
      "weighted avg       0.97      0.97      0.97        80\n",
      "\n",
      "\n",
      "Decision Tree Classifier:\n",
      "Accuracy: 0.9125\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ckd       0.98      0.88      0.93        52\n",
      "        ckd\t       0.00      0.00      0.00         0\n",
      "      notckd       0.90      0.96      0.93        28\n",
      "\n",
      "    accuracy                           0.91        80\n",
      "   macro avg       0.63      0.62      0.62        80\n",
      "weighted avg       0.95      0.91      0.93        80\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zawad\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Zawad\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Zawad\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train Decision Tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the test set using Decision Tree\n",
    "dt_y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate Random Forest Classifier\n",
    "print(\"Random Forest Classifier:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Evaluate Decision Tree Classifier\n",
    "print(\"\\nDecision Tree Classifier:\")\n",
    "dt_accuracy = accuracy_score(y_test, dt_y_pred)\n",
    "print(\"Accuracy:\", dt_accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, dt_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Classifier:\n",
      "Accuracy: 0.9875\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ckd       1.00      0.98      0.99        52\n",
      "      notckd       0.97      1.00      0.98        28\n",
      "\n",
      "    accuracy                           0.99        80\n",
      "   macro avg       0.98      0.99      0.99        80\n",
      "weighted avg       0.99      0.99      0.99        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a K-Nearest Neighbors Classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions for KNN Classifier\n",
    "knn_y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate KNN Classifier\n",
    "print(\"K-Nearest Neighbors Classifier:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, knn_y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, knn_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zawad\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"dataset/kidney_disease.csv\", na_values=['\\t?'])\n",
    "\n",
    "# Convert object columns to numeric\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_cols = ['rbc', 'pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane']\n",
    "for col in categorical_cols:\n",
    "    data[col] = label_encoder.fit_transform(data[col])\n",
    "\n",
    "# Handling Missing Values\n",
    "imputer = SimpleImputer(strategy='most_frequent')  \n",
    "data = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "\n",
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X = data.drop('classification', axis=1)\n",
    "y = data['classification']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Add Gaussian noise to numerical features\n",
    "numerical_columns = ['age', 'bp', 'sg', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wc', 'rc']\n",
    "noise_std = 0.2  # Increased noise level\n",
    "\n",
    "# Convert numerical columns to float\n",
    "X_train[numerical_columns] = X_train[numerical_columns].astype(float)\n",
    "X_test[numerical_columns] = X_test[numerical_columns].astype(float)\n",
    "\n",
    "# Add Gaussian noise to numerical features\n",
    "for col in numerical_columns:\n",
    "    noise_train = np.random.normal(0, noise_std, size=X_train[col].shape)\n",
    "    X_train[col] += noise_train\n",
    "    noise_test = np.random.normal(0, noise_std, size=X_test[col].shape)\n",
    "    X_test[col] += noise_test\n",
    "\n",
    "# Ensure that the values stay within bounds (0 and 1 for some features)\n",
    "X_train = np.clip(X_train, 0, 1)\n",
    "X_test = np.clip(X_test, 0, 1)\n",
    "\n",
    "# Define parameter grids for Random Forest and Decision Tree classifiers\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "dt_param_grid = {\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Instantiate Random Forest and Decision Tree classifiers\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Instantiate GridSearchCV for Random Forest and Decision Tree classifiers\n",
    "rf_grid_search = GridSearchCV(rf_classifier, rf_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "dt_grid_search = GridSearchCV(dt_classifier, dt_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the models\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "dt_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters for Random Forest\n",
    "print(\"Best parameters for Random Forest:\", rf_grid_search.best_params_)\n",
    "\n",
    "# Best parameters for Decision Tree\n",
    "print(\"Best parameters for Decision Tree:\", dt_grid_search.best_params_)\n",
    "\n",
    "# Predicting on the test set using best estimators from grid search\n",
    "rf_y_pred = rf_grid_search.predict(X_test)\n",
    "dt_y_pred = dt_grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate Random Forest Classifier\n",
    "print(\"\\nRandom Forest Classifier:\")\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "print(\"Accuracy:\", rf_accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, rf_y_pred))\n",
    "\n",
    "# Evaluate Decision Tree Classifier\n",
    "print(\"\\nDecision Tree Classifier:\")\n",
    "dt_accuracy = accuracy_score(y_test, dt_y_pred)\n",
    "print(\"Accuracy:\", dt_accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, dt_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zawad\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for XGBoost: {'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300, 'reg_alpha': 0, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "\n",
      "XGBoost Classifier:\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        52\n",
      "           2       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        80\n",
      "   macro avg       1.00      1.00      1.00        80\n",
      "weighted avg       1.00      1.00      1.00        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Instantiate XGBoost classifier\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "\n",
    "# Define parameter grid for XGBoost classifier\n",
    "xgb_param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV for XGBoost classifier\n",
    "xgb_grid_search = GridSearchCV(xgb_classifier, xgb_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "xgb_grid_search.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Best parameters for XGBoost\n",
    "print(\"Best parameters for XGBoost:\", xgb_grid_search.best_params_)\n",
    "\n",
    "# Predicting on the test set using best estimator from grid search\n",
    "xgb_y_pred = xgb_grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate XGBoost Classifier\n",
    "print(\"\\nXGBoost Classifier:\")\n",
    "xgb_accuracy = accuracy_score(y_test_encoded, xgb_y_pred)\n",
    "print(\"Accuracy:\", xgb_accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_encoded, xgb_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for LightGBM: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 200}\n",
      "Best LightGBM Classifier:\n",
      "Accuracy: 0.8510525070955535\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.98      0.92     42795\n",
      "         1.0       0.00      0.00      0.00       944\n",
      "         2.0       0.56      0.18      0.27      6997\n",
      "\n",
      "    accuracy                           0.85     50736\n",
      "   macro avg       0.48      0.39      0.40     50736\n",
      "weighted avg       0.81      0.85      0.81     50736\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zawad\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Zawad\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Zawad\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Initialize LightGBM Classifier\n",
    "lgb_classifier = LGBMClassifier(random_state=42)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features using RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the parameter grid for LightGBM\n",
    "param_grid_lgb = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "# Initialize LightGBM Classifier\n",
    "best_lgb_classifier = LGBMClassifier(num_leaves=50, max_depth=7, learning_rate=0.05, n_estimators=300, random_state=42)\n",
    "best_lgb_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Perform GridSearchCV for LightGBM\n",
    "grid_search_lgb = GridSearchCV(lgb_classifier, param_grid_lgb, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_lgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters for LightGBM\n",
    "best_params_lgb = grid_search_lgb.best_params_\n",
    "print(\"Best Parameters for LightGBM:\", best_params_lgb)\n",
    "\n",
    "# Train the LightGBM classifier with the best parameters\n",
    "best_lgb_classifier = LGBMClassifier(**best_params_lgb, random_state=42)\n",
    "best_lgb_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions for the best LightGBM Classifier\n",
    "best_lgb_y_pred = best_lgb_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the best LightGBM Classifier\n",
    "print(\"Best LightGBM Classifier:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, best_lgb_y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, best_lgb_y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
